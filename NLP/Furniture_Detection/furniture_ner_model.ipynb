{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Baby</td>\n",
       "      <td>B-FUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>bottle</td>\n",
       "      <td>I-FUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33892</th>\n",
       "      <td>33892</td>\n",
       "      <td>2259</td>\n",
       "      <td>displays</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33893</th>\n",
       "      <td>33893</td>\n",
       "      <td>2259</td>\n",
       "      <td>our</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33894</th>\n",
       "      <td>33894</td>\n",
       "      <td>2259</td>\n",
       "      <td>fine</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33895</th>\n",
       "      <td>33895</td>\n",
       "      <td>2259</td>\n",
       "      <td>china</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33896</th>\n",
       "      <td>33896</td>\n",
       "      <td>2259</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33897 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  sentence_id      word  label\n",
       "0               0            0       The      O\n",
       "1               1            0      Baby  B-FUR\n",
       "2               2            0    bottle  I-FUR\n",
       "3               3            0        in      O\n",
       "4               4            0       the      O\n",
       "...           ...          ...       ...    ...\n",
       "33892       33892         2259  displays      O\n",
       "33893       33893         2259       our      O\n",
       "33894       33894         2259      fine      O\n",
       "33895       33895         2259     china      O\n",
       "33896       33896         2259         .      O\n",
       "\n",
       "[33897 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"model_data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_it_list(text):\n",
    "     return str(text).split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tag</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Baby bottle in the master bedroom is where...</td>\n",
       "      <td>O B-FUR I-FUR O O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[The, Baby, bottle, in, the, master, bedroom, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I want a Baby bottle with a tufted seat and ba...</td>\n",
       "      <td>O O O B-FUR I-FUR O O O B-FUR O O O O O O</td>\n",
       "      <td>[O, O, O, B-FUR, I-FUR, O, O, O, B-FUR, O, O, ...</td>\n",
       "      <td>[I, want, a, Baby, bottle, with, a, tufted, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Baby bottle in the sunroom is where I like...</td>\n",
       "      <td>O B-FUR I-FUR O O O O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[The, Baby, bottle, in, the, sunroom, is, wher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The wooden rocking Baby bottle in the nursery ...</td>\n",
       "      <td>O O O B-FUR I-FUR O O O O O O O O O O O O</td>\n",
       "      <td>[O, O, O, B-FUR, I-FUR, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[The, wooden, rocking, Baby, bottle, in, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The Baby bottle in the game room is where my s...</td>\n",
       "      <td>O B-FUR I-FUR O O O O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[The, Baby, bottle, in, the, game, room, is, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>2255</td>\n",
       "      <td>The Trash box in the den is where I like to re...</td>\n",
       "      <td>O B-FUR I-FUR O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[The, Trash, box, in, the, den, is, where, I, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>2256</td>\n",
       "      <td>The Trash box in the den is where I like to wa...</td>\n",
       "      <td>O B-FUR I-FUR O O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[The, Trash, box, in, the, den, is, where, I, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>2257</td>\n",
       "      <td>Can you recommend a sturdy dining Trash box wi...</td>\n",
       "      <td>O O O O O O B-FUR I-FUR O O B-FUR O O O O O</td>\n",
       "      <td>[O, O, O, O, O, O, B-FUR, I-FUR, O, O, B-FUR, ...</td>\n",
       "      <td>[Can, you, recommend, a, sturdy, dining, Trash...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258</th>\n",
       "      <td>2258</td>\n",
       "      <td>Can you find me a high-top Trash box and chair...</td>\n",
       "      <td>O O O O O O B-FUR I-FUR O B-FUR O O O O O O O ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-FUR, I-FUR, O, B-FUR, O, ...</td>\n",
       "      <td>[Can, you, find, me, a, high-top, Trash, box, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>2259</td>\n",
       "      <td>The corner Trash box in the dining room displa...</td>\n",
       "      <td>O O B-FUR I-FUR O O O O O O O O O</td>\n",
       "      <td>[O, O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[The, corner, Trash, box, in, the, dining, roo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2260 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  \\\n",
       "0        0  The Baby bottle in the master bedroom is where...   \n",
       "1        1  I want a Baby bottle with a tufted seat and ba...   \n",
       "2        2  The Baby bottle in the sunroom is where I like...   \n",
       "3        3  The wooden rocking Baby bottle in the nursery ...   \n",
       "4        4  The Baby bottle in the game room is where my s...   \n",
       "...    ...                                                ...   \n",
       "2255  2255  The Trash box in the den is where I like to re...   \n",
       "2256  2256  The Trash box in the den is where I like to wa...   \n",
       "2257  2257  Can you recommend a sturdy dining Trash box wi...   \n",
       "2258  2258  Can you find me a high-top Trash box and chair...   \n",
       "2259  2259  The corner Trash box in the dining room displa...   \n",
       "\n",
       "                                                  label  \\\n",
       "0                   O B-FUR I-FUR O O O O O O O O O O O   \n",
       "1             O O O B-FUR I-FUR O O O B-FUR O O O O O O   \n",
       "2               O B-FUR I-FUR O O O O O O O O O O O O O   \n",
       "3             O O O B-FUR I-FUR O O O O O O O O O O O O   \n",
       "4               O B-FUR I-FUR O O O O O O O O O O O O O   \n",
       "...                                                 ...   \n",
       "2255                  O B-FUR I-FUR O O O O O O O O O O   \n",
       "2256                O B-FUR I-FUR O O O O O O O O O O O   \n",
       "2257        O O O O O O B-FUR I-FUR O O B-FUR O O O O O   \n",
       "2258  O O O O O O B-FUR I-FUR O B-FUR O O O O O O O ...   \n",
       "2259                  O O B-FUR I-FUR O O O O O O O O O   \n",
       "\n",
       "                                                    tag  \\\n",
       "0     [O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...   \n",
       "1     [O, O, O, B-FUR, I-FUR, O, O, O, B-FUR, O, O, ...   \n",
       "2     [O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...   \n",
       "3     [O, O, O, B-FUR, I-FUR, O, O, O, O, O, O, O, O...   \n",
       "4     [O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...   \n",
       "...                                                 ...   \n",
       "2255    [O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O]   \n",
       "2256  [O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...   \n",
       "2257  [O, O, O, O, O, O, B-FUR, I-FUR, O, O, B-FUR, ...   \n",
       "2258  [O, O, O, O, O, O, B-FUR, I-FUR, O, B-FUR, O, ...   \n",
       "2259    [O, O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [The, Baby, bottle, in, the, master, bedroom, ...  \n",
       "1     [I, want, a, Baby, bottle, with, a, tufted, se...  \n",
       "2     [The, Baby, bottle, in, the, sunroom, is, wher...  \n",
       "3     [The, wooden, rocking, Baby, bottle, in, the, ...  \n",
       "4     [The, Baby, bottle, in, the, game, room, is, w...  \n",
       "...                                                 ...  \n",
       "2255  [The, Trash, box, in, the, den, is, where, I, ...  \n",
       "2256  [The, Trash, box, in, the, den, is, where, I, ...  \n",
       "2257  [Can, you, recommend, a, sturdy, dining, Trash...  \n",
       "2258  [Can, you, find, me, a, high-top, Trash, box, ...  \n",
       "2259  [The, corner, Trash, box, in, the, dining, roo...  \n",
       "\n",
       "[2260 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns={\"Unnamed: 0\"}, inplace=True)\n",
    "data_concatenated = data.groupby(['sentence_id'], as_index = False).agg({'word': ' '.join, 'label':' '.join})\n",
    "data_concatenated[\"tag\"] = data_concatenated[\"label\"].apply(make_it_list)\n",
    "data_concatenated[\"tokens\"] = data_concatenated[\"word\"].apply(make_it_list)\n",
    "data_concatenated = data_concatenated.rename(columns={\"sentence_id\":\"id\", \"word\":\"text\"})\n",
    "data_concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tag</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Baby bottle in the master bedroom is where...</td>\n",
       "      <td>O B-FUR I-FUR O O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[The, Baby, bottle, in, the, master, bedroom, ...</td>\n",
       "      <td>[0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I want a Baby bottle with a tufted seat and ba...</td>\n",
       "      <td>O O O B-FUR I-FUR O O O B-FUR O O O O O O</td>\n",
       "      <td>[O, O, O, B-FUR, I-FUR, O, O, O, B-FUR, O, O, ...</td>\n",
       "      <td>[I, want, a, Baby, bottle, with, a, tufted, se...</td>\n",
       "      <td>[0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Baby bottle in the sunroom is where I like...</td>\n",
       "      <td>O B-FUR I-FUR O O O O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[The, Baby, bottle, in, the, sunroom, is, wher...</td>\n",
       "      <td>[0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The wooden rocking Baby bottle in the nursery ...</td>\n",
       "      <td>O O O B-FUR I-FUR O O O O O O O O O O O O</td>\n",
       "      <td>[O, O, O, B-FUR, I-FUR, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[The, wooden, rocking, Baby, bottle, in, the, ...</td>\n",
       "      <td>[0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The Baby bottle in the game room is where my s...</td>\n",
       "      <td>O B-FUR I-FUR O O O O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[The, Baby, bottle, in, the, game, room, is, w...</td>\n",
       "      <td>[0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>2255</td>\n",
       "      <td>The Trash box in the den is where I like to re...</td>\n",
       "      <td>O B-FUR I-FUR O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[The, Trash, box, in, the, den, is, where, I, ...</td>\n",
       "      <td>[0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>2256</td>\n",
       "      <td>The Trash box in the den is where I like to wa...</td>\n",
       "      <td>O B-FUR I-FUR O O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[The, Trash, box, in, the, den, is, where, I, ...</td>\n",
       "      <td>[0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>2257</td>\n",
       "      <td>Can you recommend a sturdy dining Trash box wi...</td>\n",
       "      <td>O O O O O O B-FUR I-FUR O O B-FUR O O O O O</td>\n",
       "      <td>[O, O, O, O, O, O, B-FUR, I-FUR, O, O, B-FUR, ...</td>\n",
       "      <td>[Can, you, recommend, a, sturdy, dining, Trash...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258</th>\n",
       "      <td>2258</td>\n",
       "      <td>Can you find me a high-top Trash box and chair...</td>\n",
       "      <td>O O O O O O B-FUR I-FUR O B-FUR O O O O O O O ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-FUR, I-FUR, O, B-FUR, O, ...</td>\n",
       "      <td>[Can, you, find, me, a, high-top, Trash, box, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>2259</td>\n",
       "      <td>The corner Trash box in the dining room displa...</td>\n",
       "      <td>O O B-FUR I-FUR O O O O O O O O O</td>\n",
       "      <td>[O, O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[The, corner, Trash, box, in, the, dining, roo...</td>\n",
       "      <td>[0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2260 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  \\\n",
       "0        0  The Baby bottle in the master bedroom is where...   \n",
       "1        1  I want a Baby bottle with a tufted seat and ba...   \n",
       "2        2  The Baby bottle in the sunroom is where I like...   \n",
       "3        3  The wooden rocking Baby bottle in the nursery ...   \n",
       "4        4  The Baby bottle in the game room is where my s...   \n",
       "...    ...                                                ...   \n",
       "2255  2255  The Trash box in the den is where I like to re...   \n",
       "2256  2256  The Trash box in the den is where I like to wa...   \n",
       "2257  2257  Can you recommend a sturdy dining Trash box wi...   \n",
       "2258  2258  Can you find me a high-top Trash box and chair...   \n",
       "2259  2259  The corner Trash box in the dining room displa...   \n",
       "\n",
       "                                                  label  \\\n",
       "0                   O B-FUR I-FUR O O O O O O O O O O O   \n",
       "1             O O O B-FUR I-FUR O O O B-FUR O O O O O O   \n",
       "2               O B-FUR I-FUR O O O O O O O O O O O O O   \n",
       "3             O O O B-FUR I-FUR O O O O O O O O O O O O   \n",
       "4               O B-FUR I-FUR O O O O O O O O O O O O O   \n",
       "...                                                 ...   \n",
       "2255                  O B-FUR I-FUR O O O O O O O O O O   \n",
       "2256                O B-FUR I-FUR O O O O O O O O O O O   \n",
       "2257        O O O O O O B-FUR I-FUR O O B-FUR O O O O O   \n",
       "2258  O O O O O O B-FUR I-FUR O B-FUR O O O O O O O ...   \n",
       "2259                  O O B-FUR I-FUR O O O O O O O O O   \n",
       "\n",
       "                                                    tag  \\\n",
       "0     [O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...   \n",
       "1     [O, O, O, B-FUR, I-FUR, O, O, O, B-FUR, O, O, ...   \n",
       "2     [O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...   \n",
       "3     [O, O, O, B-FUR, I-FUR, O, O, O, O, O, O, O, O...   \n",
       "4     [O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...   \n",
       "...                                                 ...   \n",
       "2255    [O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O]   \n",
       "2256  [O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...   \n",
       "2257  [O, O, O, O, O, O, B-FUR, I-FUR, O, O, B-FUR, ...   \n",
       "2258  [O, O, O, O, O, O, B-FUR, I-FUR, O, B-FUR, O, ...   \n",
       "2259    [O, O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0     [The, Baby, bottle, in, the, master, bedroom, ...   \n",
       "1     [I, want, a, Baby, bottle, with, a, tufted, se...   \n",
       "2     [The, Baby, bottle, in, the, sunroom, is, wher...   \n",
       "3     [The, wooden, rocking, Baby, bottle, in, the, ...   \n",
       "4     [The, Baby, bottle, in, the, game, room, is, w...   \n",
       "...                                                 ...   \n",
       "2255  [The, Trash, box, in, the, den, is, where, I, ...   \n",
       "2256  [The, Trash, box, in, the, den, is, where, I, ...   \n",
       "2257  [Can, you, recommend, a, sturdy, dining, Trash...   \n",
       "2258  [Can, you, find, me, a, high-top, Trash, box, ...   \n",
       "2259  [The, corner, Trash, box, in, the, dining, roo...   \n",
       "\n",
       "                                               ner_tags  \n",
       "0            [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1         [0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "2      [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3     [0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4      [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                                 ...  \n",
       "2255            [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2256         [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2257   [0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0]  \n",
       "2258  [0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "2259            [0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[2260 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#o:0\n",
    "#b-fur:1\n",
    "#i-fur:2\n",
    "\n",
    "ner = []\n",
    "for i in range(len(data_concatenated)):\n",
    "    tnk = []\n",
    "    tmp = data_concatenated.tag.iloc[i]\n",
    "    for j in tmp:\n",
    "        if j == \"O\":\n",
    "            tnk.append(0)\n",
    "        elif j == \"B-FUR\":\n",
    "            tnk.append(1)\n",
    "        else:\n",
    "            tnk.append(2)\n",
    "    ner.append(tnk)\n",
    "\n",
    "data_concatenated[\"ner_tags\"] = ner\n",
    "data_concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = np.split(data_concatenated.sample(frac=1, random_state=42),\n",
    "                            [int(.8 * len(data_concatenated)), int(.9 * len(data_concatenated))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index().reset_index().drop(columns={\"index\",\"id\"}).rename(columns={\"level_0\":\"id\"})\n",
    "df_test = df_test.reset_index().reset_index().drop(columns={\"index\",\"id\"}).rename(columns={\"level_0\":\"id\"})\n",
    "df_val = df_val.reset_index().reset_index().drop(columns={\"index\",\"id\"}).rename(columns={\"level_0\":\"id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"test_data_all_columns.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[[\"id\",\"tokens\",\"ner_tags\"]]\n",
    "df_test = df_test[[\"id\",\"tokens\",\"ner_tags\"]]\n",
    "df_val = df_val[[\"id\",\"tokens\",\"ner_tags\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"train.csv\",index=False)\n",
    "df_test.to_csv(\"test.csv\",index=False)\n",
    "df_val.to_csv(\"validation.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[The, Cushion, in, the, den, is, where, I, lik...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[I, need, to, buy, a, new, Ladderback, chair, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[I, need, a, Dresser, with, lots, of, drawers,...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[Give, me, a, Bureau, with, a, built-in, firep...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[I'm, looking, for, a, Bib, with, a, narrow, p...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>1803</td>\n",
       "      <td>[Give, me, a, coat, Wood, chair, for, the, ent...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>1804</td>\n",
       "      <td>[I, want, a, Carpet, for, my, bedroom, with, a...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>1805</td>\n",
       "      <td>[The, Rattle, in, the, bedroom, is, where, I, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>1806</td>\n",
       "      <td>[I, need, a, Bed, with, a, removable, tray, fo...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>1807</td>\n",
       "      <td>[I, want, a, Upholstered, bench, with, a, uniq...</td>\n",
       "      <td>[0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1808 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             tokens  \\\n",
       "0        0  [The, Cushion, in, the, den, is, where, I, lik...   \n",
       "1        1  [I, need, to, buy, a, new, Ladderback, chair, ...   \n",
       "2        2  [I, need, a, Dresser, with, lots, of, drawers,...   \n",
       "3        3  [Give, me, a, Bureau, with, a, built-in, firep...   \n",
       "4        4  [I'm, looking, for, a, Bib, with, a, narrow, p...   \n",
       "...    ...                                                ...   \n",
       "1803  1803  [Give, me, a, coat, Wood, chair, for, the, ent...   \n",
       "1804  1804  [I, want, a, Carpet, for, my, bedroom, with, a...   \n",
       "1805  1805  [The, Rattle, in, the, bedroom, is, where, I, ...   \n",
       "1806  1806  [I, need, a, Bed, with, a, removable, tray, fo...   \n",
       "1807  1807  [I, want, a, Upholstered, bench, with, a, uniq...   \n",
       "\n",
       "                                               ner_tags  \n",
       "0                  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1         [0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0]  \n",
       "2      [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "3     [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4     [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                 ...  \n",
       "1803  [0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1804   [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]  \n",
       "1805               [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1806         [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "1807  [0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[1808 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tokens.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Cushion',\n",
       " 'in',\n",
       " 'the',\n",
       " 'den',\n",
       " 'is',\n",
       " 'where',\n",
       " 'I',\n",
       " 'like',\n",
       " 'to',\n",
       " 'read',\n",
       " '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tokens.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA OKU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "train[\"tokens\"] = train[\"tokens\"].apply(literal_eval)\n",
    "train[\"ner_tags\"] = train[\"ner_tags\"].apply(literal_eval)\n",
    "\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test[\"tokens\"] = test[\"tokens\"].apply(literal_eval)\n",
    "test[\"ner_tags\"] = test[\"ner_tags\"].apply(literal_eval)\n",
    "\n",
    "validation = pd.read_csv(\"validation.csv\")\n",
    "validation[\"tokens\"] = validation[\"tokens\"].apply(literal_eval)\n",
    "validation[\"ner_tags\"] = validation[\"ner_tags\"].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset     \n",
    "train_dataset = Dataset.from_pandas(train)\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "validation_dataset = Dataset.from_pandas(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'tokens': ['The',\n",
       "  'Cushion',\n",
       "  'in',\n",
       "  'the',\n",
       "  'den',\n",
       "  'is',\n",
       "  'where',\n",
       "  'I',\n",
       "  'like',\n",
       "  'to',\n",
       "  'read',\n",
       "  '.'],\n",
       " 'ner_tags': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'the',\n",
       " 'cushion',\n",
       " 'in',\n",
       " 'the',\n",
       " 'den',\n",
       " 'is',\n",
       " 'where',\n",
       " 'i',\n",
       " 'like',\n",
       " 'to',\n",
       " 'read',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = train_dataset[0]\n",
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015954971313476562,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 1808,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6561497c168540efb84afc27e760913a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1808 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014164924621582031,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 226,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba4e523b6f8420497e8972836023ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/226 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013253450393676758,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 226,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbc9bb511054a378d78ff690d7de148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/226 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_test= test_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_validation = validation_dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'i',\n",
       " 'want',\n",
       " 'a',\n",
       " 'baby',\n",
       " 'bottle',\n",
       " 'with',\n",
       " 'a',\n",
       " 'tu',\n",
       " '##fted',\n",
       " 'seat',\n",
       " 'and',\n",
       " 'back',\n",
       " '##rest',\n",
       " 'for',\n",
       " 'my',\n",
       " 'vanity',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = data_concatenated.iloc[1]\n",
    "tokenized_input = tokenizer(example[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-FUR', 'I-FUR']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = [\"O\",\"B-FUR\",\"I-FUR\"]\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels = [label_list[i] for i in example[f\"ner_tags\"]]\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-FUR',\n",
       " 'I-FUR',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-FUR',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    0: \"O\",\n",
    "    1: \"B-FUR\",\n",
    "    2: \"I-FUR\"\n",
    "}\n",
    "label2id = {\n",
    "    \"O\": 0,\n",
    "    \"B-FUR\": 1,\n",
    "    \"I-FUR\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "\n",
    "batch_size = 16\n",
    "num_train_epochs = 3\n",
    "num_train_steps = (len(tokenized_train) // batch_size) * num_train_epochs\n",
    "optimizer, lr_schedule = create_optimizer(\n",
    "    init_lr=2e-5,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    "    num_warmup_steps=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 12:09:33.907328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-06 12:09:33.941893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-06 12:09:33.942202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-06 12:09:33.942959: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-06 12:09:33.943862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-06 12:09:33.944040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-06 12:09:33.944180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-06 12:09:34.392867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-06 12:09:34.393265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-06 12:09:34.393617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-06 12:09:34.393732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6136 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-03-06 12:09:35.204168: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForTokenClassification: ['vocab_projector', 'vocab_layer_norm', 'vocab_transform', 'activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'dropout_19']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForTokenClassification\n",
    "\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=3, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    tokenized_train,\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_validation_set = model.prepare_tf_dataset(\n",
    "    tokenized_validation,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "\n",
    "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub.hf_api import HfFolder\n",
    "HfFolder.save_token('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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/basakdemirok/my_furniture_ner_model into local empty directory.\n",
      "WARNING:huggingface_hub.repository:Cloning https://huggingface.co/basakdemirok/my_furniture_ner_model into local empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "\n",
    "push_to_hub_callback = PushToHubCallback(\n",
    "    output_dir=\"my_furniture_ner_model\",\n",
    "    tokenizer=tokenizer,\n",
    "    hub_token=\"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\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [metric_callback, push_to_hub_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  3/113 [..............................] - ETA: 6s - loss: 0.0033"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tm211/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:717: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - ETA: 0s - loss: 0.0069huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "113/113 [==============================] - 18s 160ms/step - loss: 0.0069 - val_loss: 0.0060 - precision: 0.9932 - recall: 0.9966 - f1: 0.9949 - accuracy: 0.9985\n",
      "Epoch 2/3\n",
      "  3/113 [..............................] - ETA: 6s - loss: 0.0059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tm211/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:717: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 6s 56ms/step - loss: 0.0059 - val_loss: 0.0060 - precision: 0.9932 - recall: 0.9966 - f1: 0.9949 - accuracy: 0.9985\n",
      "Epoch 3/3\n",
      "113/113 [==============================] - 6s 57ms/step - loss: 0.0060 - val_loss: 0.0060 - precision: 0.9932 - recall: 0.9966 - f1: 0.9949 - accuracy: 0.9985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f87c43765e0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=3, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentence = \"I want a table lamp.\"\n",
    "tokenized = tokenizer([sample_sentence], return_tensors=\"np\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[  101,  1045,  2215,  1037,  2795, 10437,  1012,   102]]), 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "outputs = model(tokenized).logits\n",
    "classes = np.argmax(outputs, axis=-1)[0]\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('[CLS]', 'O'), ('i', 'O'), ('want', 'O'), ('a', 'O'), ('table', 'B-FUR'), ('lamp', 'I-FUR'), ('.', 'O'), ('[SEP]', 'O')]\n"
     ]
    }
   ],
   "source": [
    "outputs = [(tokenizer.decode(token), model.config.id2label[id]) for token, id in zip(tokenized[\"input_ids\"][0], classes)]\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.023195505142211914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)lve/main/config.json",
       "rate": null,
       "total": 669,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a769f68a5c9b48a3b808491228b36c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/669 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018991947174072266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)\"tf_model.h5\";",
       "rate": null,
       "total": 265587984,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172f7cbba4b742488d10142e327cf63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"tf_model.h5\";:   0%|          | 0.00/266M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at basakdemirok/my_furniture_ner_model were not used when initializing TFDistilBertForTokenClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForTokenClassification were not initialized from the model checkpoint at basakdemirok/my_furniture_ner_model and are newly initialized: ['dropout_77']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019048690795898438,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)okenizer_config.json",
       "rate": null,
       "total": 360,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d95b9dcc6e4fa2bc045a250b08dbb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/360 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019399404525756836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)solve/main/vocab.txt",
       "rate": null,
       "total": 231508,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68519379e2a3422faaa40df001d42c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021187305450439453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)/main/tokenizer.json",
       "rate": null,
       "total": 711396,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2c4f8deaab462a8f8a2fd10a9b2887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015241146087646484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)cial_tokens_map.json",
       "rate": null,
       "total": 125,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605b794b98a94f2db6f7937d90fe0de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-FUR',\n",
       "  'score': 0.9924752,\n",
       "  'index': 4,\n",
       "  'word': 'table',\n",
       "  'start': 9,\n",
       "  'end': 14},\n",
       " {'entity': 'I-FUR',\n",
       "  'score': 0.992816,\n",
       "  'index': 5,\n",
       "  'word': 'lamp',\n",
       "  'start': 15,\n",
       "  'end': 19}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "text = \"I want a table lamp.\"\n",
    "classifier = pipeline(\"ner\", model=\"basakdemirok/my_furniture_ner_model\")\n",
    "classifier(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
