{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>want</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Plum</td>\n",
       "      <td>B-FUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>round</td>\n",
       "      <td>I-FUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53410</th>\n",
       "      <td>3329</td>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53411</th>\n",
       "      <td>3329</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53412</th>\n",
       "      <td>3329</td>\n",
       "      <td>living</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53413</th>\n",
       "      <td>3329</td>\n",
       "      <td>room</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53414</th>\n",
       "      <td>3329</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53415 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_id    word  label\n",
       "0                0       I      O\n",
       "1                0    want      O\n",
       "2                0       a      O\n",
       "3                0    Plum  B-FUR\n",
       "4                0   round  I-FUR\n",
       "...            ...     ...    ...\n",
       "53410         3329      to      O\n",
       "53411         3329     the      O\n",
       "53412         3329  living      O\n",
       "53413         3329    room      O\n",
       "53414         3329       .      O\n",
       "\n",
       "[53415 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"new_data_updated_on_01_04.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_it_list(text):\n",
    "     return str(text).split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tag</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I want a Plum round Desk with a trundle undern...</td>\n",
       "      <td>O O O B-FUR I-FUR I-FUR O O O O O O O O O O</td>\n",
       "      <td>[O, O, O, B-FUR, I-FUR, I-FUR, O, O, O, O, O, ...</td>\n",
       "      <td>[I, want, a, Plum, round, Desk, with, a, trund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Aquamarine linen sleek Desk next to the be...</td>\n",
       "      <td>O B-FUR I-FUR I-FUR I-FUR O O O B-FUR O O O O ...</td>\n",
       "      <td>[O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, B-FUR...</td>\n",
       "      <td>[The, Aquamarine, linen, sleek, Desk, next, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Gray linen chubby Desk in the guest room i...</td>\n",
       "      <td>O B-FUR I-FUR I-FUR I-FUR O O O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O, O,...</td>\n",
       "      <td>[The, Gray, linen, chubby, Desk, in, the, gues...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The filing crooked Khaki marble Desk in the st...</td>\n",
       "      <td>O O B-FUR I-FUR I-FUR I-FUR O O O O O O O O O O</td>\n",
       "      <td>[O, O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O,...</td>\n",
       "      <td>[The, filing, crooked, Khaki, marble, Desk, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The glass Desk added a tropical and summery vi...</td>\n",
       "      <td>O B-FUR I-FUR O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[The, glass, Desk, added, a, tropical, and, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3325</th>\n",
       "      <td>3325</td>\n",
       "      <td>The Crimson glass square Cushion in the study ...</td>\n",
       "      <td>O B-FUR I-FUR I-FUR I-FUR O O O O O O B-FUR O</td>\n",
       "      <td>[O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O, O,...</td>\n",
       "      <td>[The, Crimson, glass, square, Cushion, in, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3326</th>\n",
       "      <td>3326</td>\n",
       "      <td>I need a Cushion with lots of drawers and shel...</td>\n",
       "      <td>O O O B-FUR O O O O O B-FUR O O O O O O</td>\n",
       "      <td>[O, O, O, B-FUR, O, O, O, O, O, B-FUR, O, O, O...</td>\n",
       "      <td>[I, need, a, Cushion, with, lots, of, drawers,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3327</th>\n",
       "      <td>3327</td>\n",
       "      <td>The metal Lime small Cushion in the bathroom i...</td>\n",
       "      <td>O B-FUR I-FUR I-FUR I-FUR O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O, O,...</td>\n",
       "      <td>[The, metal, Lime, small, Cushion, in, the, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>3328</td>\n",
       "      <td>I'm looking for a Cyan crooked Cushion with a ...</td>\n",
       "      <td>O O O O B-FUR I-FUR I-FUR O O O O O O O O B-FU...</td>\n",
       "      <td>[O, O, O, O, B-FUR, I-FUR, I-FUR, O, O, O, O, ...</td>\n",
       "      <td>[I'm, looking, for, a, Cyan, crooked, Cushion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>3329</td>\n",
       "      <td>The linen Cushion added a sophisticated and el...</td>\n",
       "      <td>O B-FUR I-FUR O O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[The, linen, Cushion, added, a, sophisticated,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3330 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  \\\n",
       "0        0  I want a Plum round Desk with a trundle undern...   \n",
       "1        1  The Aquamarine linen sleek Desk next to the be...   \n",
       "2        2  The Gray linen chubby Desk in the guest room i...   \n",
       "3        3  The filing crooked Khaki marble Desk in the st...   \n",
       "4        4  The glass Desk added a tropical and summery vi...   \n",
       "...    ...                                                ...   \n",
       "3325  3325  The Crimson glass square Cushion in the study ...   \n",
       "3326  3326  I need a Cushion with lots of drawers and shel...   \n",
       "3327  3327  The metal Lime small Cushion in the bathroom i...   \n",
       "3328  3328  I'm looking for a Cyan crooked Cushion with a ...   \n",
       "3329  3329  The linen Cushion added a sophisticated and el...   \n",
       "\n",
       "                                                  label  \\\n",
       "0           O O O B-FUR I-FUR I-FUR O O O O O O O O O O   \n",
       "1     O B-FUR I-FUR I-FUR I-FUR O O O B-FUR O O O O ...   \n",
       "2     O B-FUR I-FUR I-FUR I-FUR O O O O O O O O O O O O   \n",
       "3       O O B-FUR I-FUR I-FUR I-FUR O O O O O O O O O O   \n",
       "4                     O B-FUR I-FUR O O O O O O O O O O   \n",
       "...                                                 ...   \n",
       "3325      O B-FUR I-FUR I-FUR I-FUR O O O O O O B-FUR O   \n",
       "3326            O O O B-FUR O O O O O B-FUR O O O O O O   \n",
       "3327      O B-FUR I-FUR I-FUR I-FUR O O O O O O O O O O   \n",
       "3328  O O O O B-FUR I-FUR I-FUR O O O O O O O O B-FU...   \n",
       "3329                O B-FUR I-FUR O O O O O O O O O O O   \n",
       "\n",
       "                                                    tag  \\\n",
       "0     [O, O, O, B-FUR, I-FUR, I-FUR, O, O, O, O, O, ...   \n",
       "1     [O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, B-FUR...   \n",
       "2     [O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O, O,...   \n",
       "3     [O, O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O,...   \n",
       "4       [O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O]   \n",
       "...                                                 ...   \n",
       "3325  [O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O, O,...   \n",
       "3326  [O, O, O, B-FUR, O, O, O, O, O, B-FUR, O, O, O...   \n",
       "3327  [O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O, O,...   \n",
       "3328  [O, O, O, O, B-FUR, I-FUR, I-FUR, O, O, O, O, ...   \n",
       "3329  [O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [I, want, a, Plum, round, Desk, with, a, trund...  \n",
       "1     [The, Aquamarine, linen, sleek, Desk, next, to...  \n",
       "2     [The, Gray, linen, chubby, Desk, in, the, gues...  \n",
       "3     [The, filing, crooked, Khaki, marble, Desk, in...  \n",
       "4     [The, glass, Desk, added, a, tropical, and, su...  \n",
       "...                                                 ...  \n",
       "3325  [The, Crimson, glass, square, Cushion, in, the...  \n",
       "3326  [I, need, a, Cushion, with, lots, of, drawers,...  \n",
       "3327  [The, metal, Lime, small, Cushion, in, the, ba...  \n",
       "3328  [I'm, looking, for, a, Cyan, crooked, Cushion,...  \n",
       "3329  [The, linen, Cushion, added, a, sophisticated,...  \n",
       "\n",
       "[3330 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.drop(columns={\"Unnamed: 0\"}, inplace=True)\n",
    "data_concatenated = data.groupby(['sentence_id'], as_index = False).agg({'word': ' '.join, 'label':' '.join})\n",
    "data_concatenated[\"tag\"] = data_concatenated[\"label\"].apply(make_it_list)\n",
    "data_concatenated[\"tokens\"] = data_concatenated[\"word\"].apply(make_it_list)\n",
    "data_concatenated = data_concatenated.rename(columns={\"sentence_id\":\"id\", \"word\":\"text\"})\n",
    "data_concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tag</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I want a Plum round Desk with a trundle undern...</td>\n",
       "      <td>O O O B-FUR I-FUR I-FUR O O O O O O O O O O</td>\n",
       "      <td>[O, O, O, B-FUR, I-FUR, I-FUR, O, O, O, O, O, ...</td>\n",
       "      <td>[I, want, a, Plum, round, Desk, with, a, trund...</td>\n",
       "      <td>[0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Aquamarine linen sleek Desk next to the be...</td>\n",
       "      <td>O B-FUR I-FUR I-FUR I-FUR O O O B-FUR O O O O ...</td>\n",
       "      <td>[O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, B-FUR...</td>\n",
       "      <td>[The, Aquamarine, linen, sleek, Desk, next, to...</td>\n",
       "      <td>[0, 1, 2, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Gray linen chubby Desk in the guest room i...</td>\n",
       "      <td>O B-FUR I-FUR I-FUR I-FUR O O O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O, O,...</td>\n",
       "      <td>[The, Gray, linen, chubby, Desk, in, the, gues...</td>\n",
       "      <td>[0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The filing crooked Khaki marble Desk in the st...</td>\n",
       "      <td>O O B-FUR I-FUR I-FUR I-FUR O O O O O O O O O O</td>\n",
       "      <td>[O, O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O,...</td>\n",
       "      <td>[The, filing, crooked, Khaki, marble, Desk, in...</td>\n",
       "      <td>[0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The glass Desk added a tropical and summery vi...</td>\n",
       "      <td>O B-FUR I-FUR O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[The, glass, Desk, added, a, tropical, and, su...</td>\n",
       "      <td>[0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3325</th>\n",
       "      <td>3325</td>\n",
       "      <td>The Crimson glass square Cushion in the study ...</td>\n",
       "      <td>O B-FUR I-FUR I-FUR I-FUR O O O O O O B-FUR O</td>\n",
       "      <td>[O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O, O,...</td>\n",
       "      <td>[The, Crimson, glass, square, Cushion, in, the...</td>\n",
       "      <td>[0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3326</th>\n",
       "      <td>3326</td>\n",
       "      <td>I need a Cushion with lots of drawers and shel...</td>\n",
       "      <td>O O O B-FUR O O O O O B-FUR O O O O O O</td>\n",
       "      <td>[O, O, O, B-FUR, O, O, O, O, O, B-FUR, O, O, O...</td>\n",
       "      <td>[I, need, a, Cushion, with, lots, of, drawers,...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3327</th>\n",
       "      <td>3327</td>\n",
       "      <td>The metal Lime small Cushion in the bathroom i...</td>\n",
       "      <td>O B-FUR I-FUR I-FUR I-FUR O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O, O,...</td>\n",
       "      <td>[The, metal, Lime, small, Cushion, in, the, ba...</td>\n",
       "      <td>[0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>3328</td>\n",
       "      <td>I'm looking for a Cyan crooked Cushion with a ...</td>\n",
       "      <td>O O O O B-FUR I-FUR I-FUR O O O O O O O O B-FU...</td>\n",
       "      <td>[O, O, O, O, B-FUR, I-FUR, I-FUR, O, O, O, O, ...</td>\n",
       "      <td>[I'm, looking, for, a, Cyan, crooked, Cushion,...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>3329</td>\n",
       "      <td>The linen Cushion added a sophisticated and el...</td>\n",
       "      <td>O B-FUR I-FUR O O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[The, linen, Cushion, added, a, sophisticated,...</td>\n",
       "      <td>[0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3330 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  \\\n",
       "0        0  I want a Plum round Desk with a trundle undern...   \n",
       "1        1  The Aquamarine linen sleek Desk next to the be...   \n",
       "2        2  The Gray linen chubby Desk in the guest room i...   \n",
       "3        3  The filing crooked Khaki marble Desk in the st...   \n",
       "4        4  The glass Desk added a tropical and summery vi...   \n",
       "...    ...                                                ...   \n",
       "3325  3325  The Crimson glass square Cushion in the study ...   \n",
       "3326  3326  I need a Cushion with lots of drawers and shel...   \n",
       "3327  3327  The metal Lime small Cushion in the bathroom i...   \n",
       "3328  3328  I'm looking for a Cyan crooked Cushion with a ...   \n",
       "3329  3329  The linen Cushion added a sophisticated and el...   \n",
       "\n",
       "                                                  label  \\\n",
       "0           O O O B-FUR I-FUR I-FUR O O O O O O O O O O   \n",
       "1     O B-FUR I-FUR I-FUR I-FUR O O O B-FUR O O O O ...   \n",
       "2     O B-FUR I-FUR I-FUR I-FUR O O O O O O O O O O O O   \n",
       "3       O O B-FUR I-FUR I-FUR I-FUR O O O O O O O O O O   \n",
       "4                     O B-FUR I-FUR O O O O O O O O O O   \n",
       "...                                                 ...   \n",
       "3325      O B-FUR I-FUR I-FUR I-FUR O O O O O O B-FUR O   \n",
       "3326            O O O B-FUR O O O O O B-FUR O O O O O O   \n",
       "3327      O B-FUR I-FUR I-FUR I-FUR O O O O O O O O O O   \n",
       "3328  O O O O B-FUR I-FUR I-FUR O O O O O O O O B-FU...   \n",
       "3329                O B-FUR I-FUR O O O O O O O O O O O   \n",
       "\n",
       "                                                    tag  \\\n",
       "0     [O, O, O, B-FUR, I-FUR, I-FUR, O, O, O, O, O, ...   \n",
       "1     [O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, B-FUR...   \n",
       "2     [O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O, O,...   \n",
       "3     [O, O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O,...   \n",
       "4       [O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O]   \n",
       "...                                                 ...   \n",
       "3325  [O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O, O,...   \n",
       "3326  [O, O, O, B-FUR, O, O, O, O, O, B-FUR, O, O, O...   \n",
       "3327  [O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O, O,...   \n",
       "3328  [O, O, O, O, B-FUR, I-FUR, I-FUR, O, O, O, O, ...   \n",
       "3329  [O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0     [I, want, a, Plum, round, Desk, with, a, trund...   \n",
       "1     [The, Aquamarine, linen, sleek, Desk, next, to...   \n",
       "2     [The, Gray, linen, chubby, Desk, in, the, gues...   \n",
       "3     [The, filing, crooked, Khaki, marble, Desk, in...   \n",
       "4     [The, glass, Desk, added, a, tropical, and, su...   \n",
       "...                                                 ...   \n",
       "3325  [The, Crimson, glass, square, Cushion, in, the...   \n",
       "3326  [I, need, a, Cushion, with, lots, of, drawers,...   \n",
       "3327  [The, metal, Lime, small, Cushion, in, the, ba...   \n",
       "3328  [I'm, looking, for, a, Cyan, crooked, Cushion,...   \n",
       "3329  [The, linen, Cushion, added, a, sophisticated,...   \n",
       "\n",
       "                                               ner_tags  \n",
       "0      [0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1     [0, 1, 2, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "2     [0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4               [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                                 ...  \n",
       "3325            [0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 1, 0]  \n",
       "3326   [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "3327      [0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3328  [0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3329         [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[3330 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#o:0\n",
    "#b-fur:1\n",
    "#i-fur:2\n",
    "\n",
    "ner = []\n",
    "for i in range(len(data_concatenated)):\n",
    "    tnk = []\n",
    "    tmp = data_concatenated.tag.iloc[i]\n",
    "    for j in tmp:\n",
    "        if j == \"O\":\n",
    "            tnk.append(0)\n",
    "        elif j == \"B-FUR\":\n",
    "            tnk.append(1)\n",
    "        else:\n",
    "            tnk.append(2)\n",
    "    ner.append(tnk)\n",
    "\n",
    "data_concatenated[\"ner_tags\"] = ner\n",
    "data_concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = np.split(data_concatenated.sample(frac=1, random_state=42),\n",
    "                            [int(.8 * len(data_concatenated)), int(.9 * len(data_concatenated))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tag</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>1158</td>\n",
       "      <td>The coffee triangle Gray leather Doll in the c...</td>\n",
       "      <td>O O B-FUR I-FUR I-FUR I-FUR O O O O O O O O O ...</td>\n",
       "      <td>[O, O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O,...</td>\n",
       "      <td>[The, coffee, triangle, Gray, leather, Doll, i...</td>\n",
       "      <td>[0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>1415</td>\n",
       "      <td>I'm looking for a tall Cot with a narrow profi...</td>\n",
       "      <td>O O O O B-FUR I-FUR O O O O O O O O O O O O</td>\n",
       "      <td>[O, O, O, O, B-FUR, I-FUR, O, O, O, O, O, O, O...</td>\n",
       "      <td>[I'm, looking, for, a, tall, Cot, with, a, nar...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>3012</td>\n",
       "      <td>The small Desk lamp provided a versatile and f...</td>\n",
       "      <td>O B-FUR I-FUR I-FUR O O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, I-FUR, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[The, small, Desk, lamp, provided, a, versatil...</td>\n",
       "      <td>[0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>1527</td>\n",
       "      <td>I bought a new Purple leather square coat rock...</td>\n",
       "      <td>O O O O B-FUR I-FUR I-FUR I-FUR I-FUR O O O O</td>\n",
       "      <td>[O, O, O, O, B-FUR, I-FUR, I-FUR, I-FUR, I-FUR...</td>\n",
       "      <td>[I, bought, a, new, Purple, leather, square, c...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>3241</td>\n",
       "      <td>The TV stand in the game room is where my son ...</td>\n",
       "      <td>O B-FUR I-FUR O O O O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[The, TV, stand, in, the, game, room, is, wher...</td>\n",
       "      <td>[0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>1095</td>\n",
       "      <td>The tall Yellow marble Bassinet in the bedroom...</td>\n",
       "      <td>O B-FUR I-FUR I-FUR I-FUR O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O, O,...</td>\n",
       "      <td>[The, tall, Yellow, marble, Bassinet, in, the,...</td>\n",
       "      <td>[0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>1130</td>\n",
       "      <td>The metal Crimson round Bib in the guest room ...</td>\n",
       "      <td>O B-FUR I-FUR I-FUR I-FUR O O O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O, O,...</td>\n",
       "      <td>[The, metal, Crimson, round, Bib, in, the, gue...</td>\n",
       "      <td>[0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>1294</td>\n",
       "      <td>The wicker Mobile provided a plush and comfort...</td>\n",
       "      <td>O B-FUR I-FUR O O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[The, wicker, Mobile, provided, a, plush, and,...</td>\n",
       "      <td>[0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>860</td>\n",
       "      <td>Can you please give me a Coral hexagonal Patio...</td>\n",
       "      <td>O O O O O O B-FUR I-FUR I-FUR I-FUR O O O O O ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-FUR, I-FUR, I-FUR, I-FUR,...</td>\n",
       "      <td>[Can, you, please, give, me, a, Coral, hexagon...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>3174</td>\n",
       "      <td>The Azure wooden triangle Picture in the guest...</td>\n",
       "      <td>O B-FUR I-FUR I-FUR I-FUR O O O O O O O O O O O O</td>\n",
       "      <td>[O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O, O,...</td>\n",
       "      <td>[The, Azure, wooden, triangle, Picture, in, th...</td>\n",
       "      <td>[0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  \\\n",
       "1158  1158  The coffee triangle Gray leather Doll in the c...   \n",
       "1415  1415  I'm looking for a tall Cot with a narrow profi...   \n",
       "3012  3012  The small Desk lamp provided a versatile and f...   \n",
       "1527  1527  I bought a new Purple leather square coat rock...   \n",
       "3241  3241  The TV stand in the game room is where my son ...   \n",
       "...    ...                                                ...   \n",
       "1095  1095  The tall Yellow marble Bassinet in the bedroom...   \n",
       "1130  1130  The metal Crimson round Bib in the guest room ...   \n",
       "1294  1294  The wicker Mobile provided a plush and comfort...   \n",
       "860    860  Can you please give me a Coral hexagonal Patio...   \n",
       "3174  3174  The Azure wooden triangle Picture in the guest...   \n",
       "\n",
       "                                                  label  \\\n",
       "1158  O O B-FUR I-FUR I-FUR I-FUR O O O O O O O O O ...   \n",
       "1415        O O O O B-FUR I-FUR O O O O O O O O O O O O   \n",
       "3012          O B-FUR I-FUR I-FUR O O O O O O O O O O O   \n",
       "1527      O O O O B-FUR I-FUR I-FUR I-FUR I-FUR O O O O   \n",
       "3241            O B-FUR I-FUR O O O O O O O O O O O O O   \n",
       "...                                                 ...   \n",
       "1095      O B-FUR I-FUR I-FUR I-FUR O O O O O O O O O O   \n",
       "1130  O B-FUR I-FUR I-FUR I-FUR O O O O O O O O O O O O   \n",
       "1294                O B-FUR I-FUR O O O O O O O O O O O   \n",
       "860   O O O O O O B-FUR I-FUR I-FUR I-FUR O O O O O ...   \n",
       "3174  O B-FUR I-FUR I-FUR I-FUR O O O O O O O O O O O O   \n",
       "\n",
       "                                                    tag  \\\n",
       "1158  [O, O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O,...   \n",
       "1415  [O, O, O, O, B-FUR, I-FUR, O, O, O, O, O, O, O...   \n",
       "3012  [O, B-FUR, I-FUR, I-FUR, O, O, O, O, O, O, O, ...   \n",
       "1527  [O, O, O, O, B-FUR, I-FUR, I-FUR, I-FUR, I-FUR...   \n",
       "3241  [O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...   \n",
       "...                                                 ...   \n",
       "1095  [O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O, O,...   \n",
       "1130  [O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O, O,...   \n",
       "1294  [O, B-FUR, I-FUR, O, O, O, O, O, O, O, O, O, O...   \n",
       "860   [O, O, O, O, O, O, B-FUR, I-FUR, I-FUR, I-FUR,...   \n",
       "3174  [O, B-FUR, I-FUR, I-FUR, I-FUR, O, O, O, O, O,...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "1158  [The, coffee, triangle, Gray, leather, Doll, i...   \n",
       "1415  [I'm, looking, for, a, tall, Cot, with, a, nar...   \n",
       "3012  [The, small, Desk, lamp, provided, a, versatil...   \n",
       "1527  [I, bought, a, new, Purple, leather, square, c...   \n",
       "3241  [The, TV, stand, in, the, game, room, is, wher...   \n",
       "...                                                 ...   \n",
       "1095  [The, tall, Yellow, marble, Bassinet, in, the,...   \n",
       "1130  [The, metal, Crimson, round, Bib, in, the, gue...   \n",
       "1294  [The, wicker, Mobile, provided, a, plush, and,...   \n",
       "860   [Can, you, please, give, me, a, Coral, hexagon...   \n",
       "3174  [The, Azure, wooden, triangle, Picture, in, th...   \n",
       "\n",
       "                                               ner_tags  \n",
       "1158  [0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1415  [0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3012      [0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1527            [0, 0, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0]  \n",
       "3241   [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                                 ...  \n",
       "1095      [0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1130  [0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1294         [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "860   [0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, ...  \n",
       "3174  [0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[333 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index().reset_index().drop(columns={\"index\",\"id\"}).rename(columns={\"level_0\":\"id\"})\n",
    "df_test = df_test.reset_index().reset_index().drop(columns={\"index\",\"id\"}).rename(columns={\"level_0\":\"id\"})\n",
    "df_val = df_val.reset_index().reset_index().drop(columns={\"index\",\"id\"}).rename(columns={\"level_0\":\"id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"test_data_all_columns.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[[\"id\",\"tokens\",\"ner_tags\"]]\n",
    "df_test = df_test[[\"id\",\"tokens\",\"ner_tags\"]]\n",
    "df_val = df_val[[\"id\",\"tokens\",\"ner_tags\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"train.csv\",index=False)\n",
    "df_test.to_csv(\"test.csv\",index=False)\n",
    "df_val.to_csv(\"validation.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[I, bought, a, new, Curtains, for, my, home, o...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[I'm, looking, for, a, floor, Wing, chair, wit...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[I, need, a, filing, Blue, sleek, Trash, for, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[I, need, a, Cantilever, chair, to, put, my, p...</td>\n",
       "      <td>[0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[The, Hope, chest, in, the, living, room, is, ...</td>\n",
       "      <td>[0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>2659</td>\n",
       "      <td>[The, wooden, Black, tall, Hat, stand, at, the...</td>\n",
       "      <td>[0, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>2660</td>\n",
       "      <td>[The, crooked, glass, Folding, chair, added, a...</td>\n",
       "      <td>[0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2661</th>\n",
       "      <td>2661</td>\n",
       "      <td>[The, Olden, metal, low, Speaker, in, the, den...</td>\n",
       "      <td>[0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2662</th>\n",
       "      <td>2662</td>\n",
       "      <td>[Can, you, recommend, a, sturdy, dining, Maroo...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>2663</td>\n",
       "      <td>[I'm, in, the, market, for, a, Maroon, square,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2664 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             tokens  \\\n",
       "0        0  [I, bought, a, new, Curtains, for, my, home, o...   \n",
       "1        1  [I'm, looking, for, a, floor, Wing, chair, wit...   \n",
       "2        2  [I, need, a, filing, Blue, sleek, Trash, for, ...   \n",
       "3        3  [I, need, a, Cantilever, chair, to, put, my, p...   \n",
       "4        4  [The, Hope, chest, in, the, living, room, is, ...   \n",
       "...    ...                                                ...   \n",
       "2659  2659  [The, wooden, Black, tall, Hat, stand, at, the...   \n",
       "2660  2660  [The, crooked, glass, Folding, chair, added, a...   \n",
       "2661  2661  [The, Olden, metal, low, Speaker, in, the, den...   \n",
       "2662  2662  [Can, you, recommend, a, sturdy, dining, Maroo...   \n",
       "2663  2663  [I'm, in, the, market, for, a, Maroon, square,...   \n",
       "\n",
       "                                               ner_tags  \n",
       "0                        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]  \n",
       "1      [0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2     [0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4            [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                                 ...  \n",
       "2659  [0, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2660   [0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2661   [0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2662  [0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 1, 0, 0, 0, ...  \n",
       "2663  [0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[2664 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tokens.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'bought', 'a', 'new', 'Curtains', 'for', 'my', 'home', 'office', '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tokens.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA OKU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "train[\"tokens\"] = train[\"tokens\"].apply(literal_eval)\n",
    "train[\"ner_tags\"] = train[\"ner_tags\"].apply(literal_eval)\n",
    "\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test[\"tokens\"] = test[\"tokens\"].apply(literal_eval)\n",
    "test[\"ner_tags\"] = test[\"ner_tags\"].apply(literal_eval)\n",
    "\n",
    "validation = pd.read_csv(\"validation.csv\")\n",
    "validation[\"tokens\"] = validation[\"tokens\"].apply(literal_eval)\n",
    "validation[\"ner_tags\"] = validation[\"ner_tags\"].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset     \n",
    "train_dataset = Dataset.from_pandas(train)\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "validation_dataset = Dataset.from_pandas(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'tokens': ['I',\n",
       "  'bought',\n",
       "  'a',\n",
       "  'new',\n",
       "  'Curtains',\n",
       "  'for',\n",
       "  'my',\n",
       "  'home',\n",
       "  'office',\n",
       "  '.'],\n",
       " 'ner_tags': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'i',\n",
       " 'bought',\n",
       " 'a',\n",
       " 'new',\n",
       " 'curtains',\n",
       " 'for',\n",
       " 'my',\n",
       " 'home',\n",
       " 'office',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = train_dataset[0]\n",
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01851034164428711,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 2664,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44dd129564e4c8d9c075e96532fa8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2664 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012469053268432617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 333,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca8fa089ea341aa9172e310279101c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/333 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0177152156829834,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 333,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c605d3afc22473cba99bfd960769a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/333 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_test= test_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_validation = validation_dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'the',\n",
       " 'aqua',\n",
       " '##marine',\n",
       " 'linen',\n",
       " 'sleek',\n",
       " 'desk',\n",
       " 'next',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bed',\n",
       " 'is',\n",
       " 'where',\n",
       " 'i',\n",
       " 'keep',\n",
       " 'my',\n",
       " 'alarm',\n",
       " 'clock',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = data_concatenated.iloc[1]\n",
    "tokenized_input = tokenizer(example[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-FUR', 'I-FUR']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = [\"O\",\"B-FUR\",\"I-FUR\"]\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels = [label_list[i] for i in example[f\"ner_tags\"]]\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-FUR',\n",
       " 'I-FUR',\n",
       " 'I-FUR',\n",
       " 'I-FUR',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-FUR',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    0: \"O\",\n",
    "    1: \"B-FUR\",\n",
    "    2: \"I-FUR\"\n",
    "}\n",
    "label2id = {\n",
    "    \"O\": 0,\n",
    "    \"B-FUR\": 1,\n",
    "    \"I-FUR\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "\n",
    "batch_size = 16\n",
    "num_train_epochs = 3\n",
    "num_train_steps = (len(tokenized_train) // batch_size) * num_train_epochs\n",
    "optimizer, lr_schedule = create_optimizer(\n",
    "    init_lr=2e-5,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    "    num_warmup_steps=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 16:24:41.661457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-01 16:24:41.699815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-01 16:24:41.700434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-01 16:24:41.701758: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-01 16:24:41.702920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-01 16:24:41.703361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-01 16:24:41.703713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-01 16:24:42.537996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-01 16:24:42.538243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-01 16:24:42.538397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-01 16:24:42.538537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6136 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-04-01 16:24:43.339728: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForTokenClassification: ['vocab_transform', 'activation_13', 'vocab_projector', 'vocab_layer_norm']\n",
      "- This IS expected if you are initializing TFDistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'dropout_19']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForTokenClassification\n",
    "\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=3, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    tokenized_train,\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_validation_set = model.prepare_tf_dataset(\n",
    "    tokenized_validation,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "\n",
    "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub.hf_api import HfFolder\n",
    "HfFolder.save_token('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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tm211/BASAK/BITIRME/DENEME/my_furniture_ner_model is already a clone of https://huggingface.co/basakdemirok/my_furniture_ner_model. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "\n",
    "push_to_hub_callback = PushToHubCallback(\n",
    "    output_dir=\"my_furniture_ner_model\",\n",
    "    tokenizer=tokenizer,\n",
    "    hub_token=\"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\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [metric_callback, push_to_hub_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  2/166 [..............................] - ETA: 9s - loss: 1.1608   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tm211/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:717: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - ETA: 0s - loss: 0.1723huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "166/166 [==============================] - 38s 168ms/step - loss: 0.1723 - val_loss: 0.0151 - precision: 0.9692 - recall: 0.9888 - f1: 0.9789 - accuracy: 0.9964\n",
      "Epoch 2/3\n",
      "  4/166 [..............................] - ETA: 8s - loss: 0.0105"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tm211/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:717: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 9s 55ms/step - loss: 0.0077 - val_loss: 0.0017 - precision: 1.0000 - recall: 1.0000 - f1: 1.0000 - accuracy: 0.9998\n",
      "Epoch 3/3\n",
      "166/166 [==============================] - 9s 57ms/step - loss: 0.0032 - val_loss: 0.0011 - precision: 0.9978 - recall: 0.9978 - f1: 0.9978 - accuracy: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8128391fd0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=3, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentence = \"I want a table lamp and a tv.\"\n",
    "tokenized = tokenizer([sample_sentence], return_tensors=\"np\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[  101,  1045,  2215,  1037,  2795, 10437,  1998,  1037,  2694,\n",
       "         1012,   102]]), 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 2 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "outputs = model(tokenized).logits\n",
    "classes = np.argmax(outputs, axis=-1)[0]\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('[CLS]', 'O'), ('i', 'O'), ('want', 'O'), ('a', 'O'), ('table', 'B-FUR'), ('lamp', 'I-FUR'), ('and', 'O'), ('a', 'O'), ('tv', 'B-FUR'), ('.', 'O'), ('[SEP]', 'O')]\n"
     ]
    }
   ],
   "source": [
    "outputs = [(tokenizer.decode(token), model.config.id2label[id]) for token, id in zip(tokenized[\"input_ids\"][0], classes)]\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
